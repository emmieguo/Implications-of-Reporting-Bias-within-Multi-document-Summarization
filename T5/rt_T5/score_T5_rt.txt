ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.08281265761783269, recall=0.22844996141711368, fmeasure=0.11793516114855317), mid=Score(precision=0.09373572553665889, recall=0.2524222281417999, fmeasure=0.1315417381101801), high=Score(precision=0.10491412038602979, recall=0.27749659238888486, fmeasure=0.14477882649231125)), 'rouge2': AggregateScore(low=Score(precision=0.01696296547653049, recall=0.04823015788115693, fmeasure=0.02441772910803124), mid=Score(precision=0.022552555661798715, recall=0.06472034594110435, fmeasure=0.032009832954562105), high=Score(precision=0.028896691488537164, recall=0.08137044049996016, fmeasure=0.04007326803087536)), 'rougeL': AggregateScore(low=Score(precision=0.06803490430584949, recall=0.1856522282910794, fmeasure=0.09640685184371768), mid=Score(precision=0.07589212904943152, recall=0.20732075879185188, fmeasure=0.1068986921301395), high=Score(precision=0.0853801792554263, recall=0.23080727919169355, fmeasure=0.11802315374332305)), 'rougeLsum': AggregateScore(low=Score(precision=0.06682354825028197, recall=0.18497324700415882, fmeasure=0.0954461914631673), mid=Score(precision=0.07602453881949124, recall=0.208089597000434, fmeasure=0.10697165383712026), high=Score(precision=0.08551798919603817, recall=0.2328441892399031, fmeasure=0.11922230769429845))}

BERT Scores: {'precision': 0.8154438257217407, 'recall': 0.8467346930503845, 'f1': 0.8306728452444077}

Data Statistics: {'avg_doc_length': 1833.71, 'avg_summary_length': 52.15, 'compression_ratio': 0.028439611498001317}