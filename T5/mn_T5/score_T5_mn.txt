ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.4292658631654756, recall=0.14155155525890248, fmeasure=0.2103837445338063), mid=Score(precision=0.45517659027885815, recall=0.15448761379265255, fmeasure=0.22677669149079815), high=Score(precision=0.4794130153687583, recall=0.16757371490343906, fmeasure=0.24331041431367456)), 'rouge2': AggregateScore(low=Score(precision=0.10037127785501794, recall=0.03405893031494228, fmeasure=0.05005655132209528), mid=Score(precision=0.11909294073021426, recall=0.04221823424927544, fmeasure=0.06106497008182722), high=Score(precision=0.13856650096566914, recall=0.052482983900250454, fmeasure=0.07427048495670809)), 'rougeL': AggregateScore(low=Score(precision=0.2501561927616732, recall=0.08248276357515229, fmeasure=0.122713037754415), mid=Score(precision=0.26518957375535174, recall=0.09086401980255734, fmeasure=0.13284011161350262), high=Score(precision=0.28359649993333924, recall=0.09996066042441953, fmeasure=0.1442007436923643)), 'rougeLsum': AggregateScore(low=Score(precision=0.2488440487375128, recall=0.08219986891405609, fmeasure=0.12199580216015843), mid=Score(precision=0.2650200660272576, recall=0.09032449265425152, fmeasure=0.13222316287230912), high=Score(precision=0.28404770496263837, recall=0.10022783954866434, fmeasure=0.14462358529470692))}

BERT Scores: {'precision': 0.8377136480808258, 'recall': 0.8129355388879776, 'f1': 0.8248847210407257}

Data Statistics: {'avg_doc_length': 1717.13, 'avg_summary_length': 69.32, 'compression_ratio': 0.04036968662826926}